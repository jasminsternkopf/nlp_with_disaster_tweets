This repository contains code comparing Latent Semantic Indexing (LSI) with a basic Support Vector Machines model and two supervised learning methods based on LSI and Partial Least Squares: Semantic Indexing based on Partial Least Squares (SIPLS) and Local Semantic Indexing based on Partial Least Squares (LSIPLS). We compare these techniques through a binary classification problem which is posed on the platform kaggle.com: "Real or Not? NLP with Disaster Tweets" (https://www.kaggle.com/c/nlp-getting-started/overview).
To download the corresponding training and test set, it is neccessary to posess a kaggle account and to agree to the competition rules. Please do that and download the data into a subdirectory called "data". Some participants discovered that the ground truth of the test set was openly available. You can download it for example from people presenting their notebooks in which they used the original labels of the test set (https://www.kaggle.com/szelee/a-real-disaster-leaked-label). Please download this file into your data folder, too. It should be named "submission.csv".

The output of "main.py" will be the test and training scores of the of the respective model depending on the dimension of the room in which the data is projected by LSI, SIPLS or LSIPLS, the hyperparameters which have been chosen by GridSearchCV for the corresponding model and a plot of those scores. Feel free to use this code and modify it in any way you need.